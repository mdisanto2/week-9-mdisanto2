{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![DSB logo](img/Dolan.jpg)\n",
    "# Pandas Data Structure\n",
    "\n",
    "## PD4E Chapter 2\n",
    "### How do you read/manipulate/store data in Python?\n",
    "\n",
    "_Lecture Slides v 0.1, Developed by Dr. Jie Tao_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What You Learned in Python/Pandas that could Apply Here\n",
    "\n",
    "You will need following knowledge from the first half of this course:\n",
    "1. containers\n",
    "2. function definition and calling\n",
    "3. subsetting and indexing\n",
    "4. Loading data in Pandas\n",
    "5. Slicing and subsetting\n",
    "6. Basic knowledge of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What You will Learn in this Chapter\n",
    "You will learn following techniques in this chapter:\n",
    "1. Load in manual data\n",
    "2. The `Series` object\n",
    "3. Basic operations on `Series`\n",
    "4. The `DataFrame` object\n",
    "5. Conditional subsetting and fancy slicing/indexing\n",
    "6. Saving data to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Creating a Series\n",
    "\n",
    "- Manually creating data is an important skill for testing your code\n",
    "    - You do not have to load data from a file, like we did last week\n",
    "    - This type of testing is particularly useful when you want to find out what happened with an error\n",
    "- pandas `Series` is a _one-dimensional_ container similar to a Python _list_\n",
    "    - We saw `Series` as a column in a pandas `DataFrame`\n",
    "    - Each `DataFrame` can be considered as a `dict` of `Series`\n",
    "        - the `keys` of `dict` are the _column names_, and the `values` are `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    banana\n",
       "1        42\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since `Series` and `list` are similar, \n",
    "# the easiest way to create a `Series` is to pass a `list`\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series(['banana', 42])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Few Pointers\n",
    "\n",
    "- We passed a `list` `['banana', 42]` to a the `Series` constructor, and a `Series` object is created\n",
    "    - since we passed a `list` with mixed data types (`str` and `int`), the `Series` has a data type of `object`\n",
    "        - `object` is the most inclusive data type in `pandas`, however, we do not want it unless we have no other choice\n",
    "    - When passing a `list`, `pandas` automatically assign row numbers (`0`, `1`) to the `Series`\n",
    "    - But we can also assign row names to the `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person         Wes McKinney\n",
       "Who       Creator of Pandas\n",
       "Name: Info, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating another `Series` with assigning index values and name of `Series`\n",
    "pandas_creater_series = pd.Series(['Wes McKinney', 'Creator of Pandas'], # A list of strings\n",
    "                                 index=['Person', 'Who'], # index values\n",
    "                                 name ='Info') # name of `Series`\n",
    "pandas_creater_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k1    v1\n",
       "k2    v2\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also pass a `dict` as a `Series`\n",
    "# keys become series index values\n",
    "dict_series = pd.Series({'k1':'v1', 'k2':'v2'})\n",
    "dict_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Creating a DataFrame\n",
    "\n",
    "- As said earlier, a `DataFrame` object can be considered as a `dict` of `Series`\n",
    "    - in practice, we use `dicts` as the most popular way of creating a `DataFrame`\n",
    "    - but instead of using `Series`, we often use `lists`, since they are very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Born</th>\n",
       "      <th>Died</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rosaline Franklin</td>\n",
       "      <td>Chemist</td>\n",
       "      <td>1920-07-25</td>\n",
       "      <td>1958-04-16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William Gosset</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>1876-06-13</td>\n",
       "      <td>1937-10-16</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name    Occupation        Born        Died  Age\n",
       "0  Rosaline Franklin       Chemist  1920-07-25  1958-04-16   37\n",
       "1     William Gosset  Statistician  1876-06-13  1937-10-16   61"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a DF from a `dict`\n",
    "scientists_df = pd.DataFrame(\n",
    "    {'Name': ['Rosaline Franklin','William Gosset'],\n",
    "     'Occupation':['Chemist','Statistician'],\n",
    "     'Born':['1920-07-25', '1876-06-13'],\n",
    "     'Died':['1958-04-16', '1937-10-16'],\n",
    "     'Age':[37,61]})\n",
    "scientists_df\n",
    "# note that the order to columns/rows are not guaranteed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# If We Want Them in ORDER\n",
    "- Note that the order to columns/rows are not guaranteed, since `pandas` arrange `dict keys` in the alphabetical order by default\n",
    "- If we want to specific the order of columns, we should use the `columns=` argument in the `pd.DataFrame()` constructor\n",
    "    - Normally we pass a `list` of `strings` to this argument\n",
    "\n",
    "- If we also want to pass index values, similar to `Series`, we can use the `index=` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Born</th>\n",
       "      <th>Died</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rosaline Franklin</th>\n",
       "      <td>Chemist</td>\n",
       "      <td>1920-07-25</td>\n",
       "      <td>1958-04-16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>William Gosset</th>\n",
       "      <td>Statistician</td>\n",
       "      <td>1876-06-13</td>\n",
       "      <td>1937-10-16</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Occupation        Born        Died  Age\n",
       "Rosaline Franklin       Chemist  1920-07-25  1958-04-16   37\n",
       "William Gosset     Statistician  1876-06-13  1937-10-16   61"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scientists_df = pd.DataFrame(\n",
    "data={'Occupation':['Chemist','Statistician'],\n",
    "'Born':['1920-07-25', '1876-06-13'],\n",
    "'Died':['1958-04-16', '1937-10-16'],\n",
    "'Age':[37,61]},\n",
    "index=['Rosaline Franklin','William Gosset'],\n",
    "columns=['Occupation', 'Born','Died','Age'])\n",
    "\n",
    "scientists_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Occupation       Chemist\n",
       "Born          1920-07-25\n",
       "Died          1958-04-16\n",
       "Age                   37\n",
       "Name: Rosaline Franklin, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that not only a column, a row in a DF is also a `Series`\n",
    "# we can use the row index label to slice a row\n",
    "first_row = scientists_df.loc['Rosaline Franklin']\n",
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can test the type of `first_row` as `Series`\n",
    "type(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Occupation', 'Born', 'Died', 'Age'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that when we slice a row, \n",
    "# the column names in the orginal DF become index values of the `Series`\n",
    "# similarly, since we know `Series` are similar to `dict`, we can use `.keys()` method\n",
    "first_row.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chemist', '1920-07-25', '1958-04-16', 37], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Series support an attribute to access its values\n",
    "first_row.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Quick Note about Methods and Attributes\n",
    "- Unlike functions, methods and attributes are both associated with a certain object (`DataFrame`, `Series`)\n",
    "    - we use dot notation (`.`) for both methods and attributes\n",
    "- Difference between methods and attributes are:\n",
    "    - Methods are some calculation or operation toward the object, you can think of them as __functions__ toward a certain type of object\n",
    "    - Attributes are some properties of the object, which can are used to define an object\n",
    "        - `[]` are also attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Occupation'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can get the first index of `first_row` using an attribute\n",
    "first_row.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Series Methods\n",
    "\n",
    "- `Series` objects support a group of calculations, which is inhereted from `numpy` [reference](https://docs.scipy.org/doc/numpy/user/)\n",
    "    - below methods only work for numeric valued `Series` \n",
    "    - Refer to __Table 2.2__ on pp.31 in PD4E for a more comprehensive of `Series` methods \n",
    "        - __Maybe handy when you are working on your assignment__\n",
    "```python\n",
    "s.mean()\n",
    "s.min()\n",
    "s.max()\n",
    "s.std()\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average age: 49.0\n",
      "min age 37\n",
      "max age 61\n",
      "age standard deviation 16.97056274847714\n"
     ]
    }
   ],
   "source": [
    "# ages is a numeric valued `Series`\n",
    "ages = scientists_df.Age\n",
    "\n",
    "print('average age:', ages.mean())\n",
    "print('min age', ages.min())\n",
    "print('max age', ages.max())\n",
    "print('age standard deviation', ages.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Boolean Subsetting of Series\n",
    "- Last week, we learned how to use specific conditions to subset a DataFrame/Series\n",
    "- however, more typically we do not know these specific conditions\n",
    "    - rather than testing whether values meet (or don't meet) certain condition\n",
    "    \n",
    "    \n",
    "We need a larger dataset for illustration.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./data/scientists.csv' does not exist: b'./data/scientists.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2472a6e2007a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# please change your PATH to `'/srv/data/my_shared_data_folder/ba505-data/scientists.csv'`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmore_scientists_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/scientists.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmore_scientists_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./data/scientists.csv' does not exist: b'./data/scientists.csv'"
     ]
    }
   ],
   "source": [
    "# please change your PATH to `'/srv/data/my_shared_data_folder/ba505-data/scientists.csv'`\n",
    "more_scientists_df = pd.read_csv('./data/scientists.csv')\n",
    "ages = more_scientists_df.Age\n",
    "ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get basic stats of `ages`\n",
    "ages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# we can filter values of ages by\n",
    "# whether they are greater than the mean age or not\n",
    "ages[ages > ages.mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# WHY? Let's look at what did the inner logical expression return\n",
    "ages > ages.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# what's the type of above results?\n",
    "type(ages > ages.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Now we know that we can __filter__ `Series` values based on a boolean `Series` of the same length. \n",
    "    - only values associated with `True` values are returned\n",
    "- Since we know that, we can manually create a `Series` of boolean values for filtering purposes\n",
    "    - See an example on pp.32-33 for manually filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas Operations Automatically Broadcast\n",
    "- Since we already learned __iteration__(e.g., _for loops_), we know if we want to apply an operation toward a collection of items (e.g. `lists`, `dicts`), we need to embed the operation in a loop\n",
    "- However, many of `Pandas` operations that work on `Series` and/or `DataFrames` work on the entire vector (all elements) simultaneously\n",
    "    - this is how `Pandas` makes calculations on large datasets very fast\n",
    "    - this is referred as _broadcasting_, in which results are automatically _aligned_ and _vectorized_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# vector of same length\n",
    "ages + ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Vectors and integers (scalar values)\n",
    "ages + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# vectors with different lengths\n",
    "# Note that `NaN` means not a number\n",
    "# only matched values can work, the rest of the `Series` returns as `NaN`\n",
    "ages + pd.Series([1, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# vectors with common index are automatically aligned\n",
    "\n",
    "# create a `Series` of `ages` in _reversed order_\n",
    "rev_ages = ages.sort_index(ascending=False)\n",
    "\n",
    "rev_ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Your Turn Here\n",
    "\n",
    "Inspect the results closely, and tell me why the results is like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rev_ages + ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# a little help\n",
    "ages * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DataFrames and Series are Similar\n",
    "\n",
    "- As said before, DataFrames are essentially dictionaries of Series\n",
    "    - so most of the characteristics of Series can be applied to DataFrames\n",
    "    - in detail, both _boolean subsetting_ and _broadcasting_ can be applied to DFs\n",
    "        - Refer to __Table 2.3__ (pp.37) for more details on DF subsetting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# boolean subsetting\n",
    "more_scientists_df[more_scientists_df.Age > more_scientists_df.Age.mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# broadcasting\n",
    "\n",
    "more_scientists_df * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Making Changes to Series & DataFrames\n",
    "\n",
    "- Subsetting/Slicing/Filtering data in our Series and DataFrames are very useful techniques\n",
    "    - you should practice a lot of these skills since you will need them badly in BA 545\n",
    "- In some other scenarios, we also need to change values in our data\n",
    "    - for instance, in data mining/machine learning, we process data so our models can take them\n",
    "- Three types of changes are popular\n",
    "    1. adding additional columns - transfer values in the orginal column in a new column\n",
    "    2. Directly changing a column - most direct, but not recommended at most times\n",
    "    3. Dropping a column - maybe useful, but not recommended at most times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Adding Additional Columns\n",
    "- Usually, we create a new column to store the processed values from an original column\n",
    "    - Benefits of this include:\n",
    "        - we keep the original column so we can compare the original values and the processed values\n",
    "        - if the processed values are not as expected, we can always start over\n",
    "        - __re-traceability/re-producibility__: in any analysis, other people should be able to replicate your results from the original data, following your documented steps\n",
    "- Consider following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# types of `born` and `died` are `object` which means they are `strings`\n",
    "print(more_scientists_df.Born.dtype)\n",
    "print(more_scientists_df.Died.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# format `born` as a datetime\n",
    "# Pandas provides a function/method `.to_datetime()` for that\n",
    "# you need to specify the format of your date/time\n",
    "# refer to the method docs for more details: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html\n",
    "\n",
    "born_datetime = pd.to_datetime(more_scientists_df['Born'], format='%Y-%m-%d')\n",
    "born_datetime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Similar operation to `Died`\n",
    "died_datetime = pd.to_datetime(more_scientists_df['Died'], format='%Y-%m-%d')\n",
    "died_datetime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# insert these new columns (`born_datetime`, `died_datetime`) back to the DF\n",
    "# we use a __multi-assignment__ statement here - refer to appendix Q in PD4E for more details\n",
    "more_scientists_df['born_dt'], more_scientists_df['died_dt'] = (born_datetime, died_datetime)\n",
    "\n",
    "# now let's test if the converted column and the original column are aligned\n",
    "# use `Born` as an example\n",
    "more_scientists_df[['Born', 'born_dt']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# we can also test if the new columns are successfully inserted\n",
    "# there are multiple ways\n",
    "# in the text book (pp.39), the method use `.shape` attribute\n",
    "# we use column names to test if the two new columns appear\n",
    "more_scientists_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Directly Change a Column\n",
    "- Even though we do not recommend this approach, sometimes this is very useful\n",
    "    - particularly when we created a copy of the data, then we can change the values directly without changing the origial data\n",
    "    - no matter under what circumstances, changing the original data is __FORBIDDEN__.\n",
    "- We can assign new values to a DataFrame (in a column particularly)\n",
    "    - You may receive a warning from Pandas trying to stop you from changing the original data\n",
    "- More complicated examples are provided in Chapter 9\n",
    "- Read PD4E pp.40-42 for more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a copy of 'more_scientist_df'\n",
    "# a MUST-DO when you want to change the values directly\n",
    "more_scientists_df_copy = more_scientists_df.copy()\n",
    "\n",
    "# let shuffle the values of `Age`\n",
    "import random\n",
    "# set a seed so the randomness is always the same\n",
    "# we will see different uses of this multiple times\n",
    "random.seed(2019)\n",
    "random.shuffle(more_scientists_df_copy.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "more_scientists_df_copy.Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Compare with original\n",
    "more_scientists_df.Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Dropping Values\n",
    "\n",
    "- Dropping a column is not recommended\n",
    "- To drop a column, we can either:\n",
    "    - Select the columns we want to keep, and store in a new DataFrame\n",
    "    - Select column to drop using the `.drop()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "more_scientists_df_copy.drop(['Age'], inplace=True, axis=1)\n",
    "# Age column is dropped\n",
    "more_scientists_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Importing and Exporting Data\n",
    "\n",
    "- Comma Separated Values (csv) are the _most flexible_ data storage type.\n",
    "    - for each row, the column values are separated by a comma (`,`), or a tab (which makes it a TSV file)\n",
    "    - this is the preferred way of sharing data and collaboration\n",
    "    - Pandas provides a `.to_csv()` method for storing DataFrame/Series in CSV/TSV\n",
    "    - refer to the [docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dirName = 'data'\n",
    " \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "more_scientists_df_copy.to_csv('./data/more_scientists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Importing and Exporting Data - Cont'd\n",
    "\n",
    "- Python has a way to _pickle_ data\n",
    "- _Pickle_ is Python's way of serializing and saving data in a binary format\n",
    "- Different from `.to_csv()`, pickle preservses data type in your data\n",
    "    - for instance, if you save a list in a DataFrame to CSV, the list is converted to a string `'[', 'element1', ..., ']'`\n",
    "    - where as pickle can save lists and dicts as themselves\n",
    "    \n",
    "    - refer to the pickle [docs](https://docs.python.org/3/library/pickle.html) here\n",
    "    - similarly, there is a file type called JSON ([docs](https://docs.python.org/3/library/json.html)) that is suitable for saving dicts and DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# write to pickle\n",
    "# note that the file is named as `.pickle`\n",
    "more_scientists_df_copy.born_dt.to_pickle('./data/scientist_born_dates.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Read from pickle\n",
    "# note that the datetime date type is preserved\n",
    "born_dates = pd.read_pickle('./data/scientist_born_dates.pickle')\n",
    "born_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Your Turn Here\n",
    "\n",
    "Finish exercises below by following instructions of each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Q1. Coding Completion Problem\n",
    "\n",
    "Given a random `Series` of integers, find elements that are divisible by 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# this code block generates a `Series` of 20 integers between 1 and 19\n",
    "import numpy as np\n",
    "my_series = pd.Series(np.random.randint(1, 20, 20))\n",
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# write your code here to find numbers in `my_series` \n",
    "# that are divisible by 3\n",
    "# hint: you just need one line of code\n",
    "\n",
    "my_series_df = my_series[my_series % 3 ==0]\n",
    "print(my_series_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# extra points: change values that are non-divisible by 3 to `NaN`\n",
    "# hint: you just need another line of code\n",
    "my_series_df = my_series[my_series % 3 == 0]\n",
    "\n",
    "print(my_series_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Q2. Coding Completion Problem\n",
    "\n",
    "Given a DataFrame with two columns of random dates (`date1`, `date2`), calculate `months` between the two dates in each row in the third column (`year_diff`). Then save the DataFrame as a pickle file (`./data/dates_calc.pickle`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# function to generate random dates\n",
    "import random\n",
    "def rng_dates(n,start_date, end_date):\n",
    "    # hat tip to Peilonrayz\n",
    "    date_lst = []\n",
    "    for i in range(n):\n",
    "        date_lst.append(pd.to_datetime(random.choice(pd.bdate_range(start_date, end_date))))\n",
    "    return date_lst\n",
    "        \n",
    "date_series1 = pd.Series(rng_dates(10, '2016-01-01', '2017-12-31')).sort_values().reset_index(drop=True)\n",
    "date_series2 = pd.Series(rng_dates(10, '2018-01-01', '2019-12-31')).sort_values().reset_index(drop=True)\n",
    "date_df = pd.concat([date_series1, date_series2], axis=1)\n",
    "date_df.columns = ['date1', 'date2']\n",
    "date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate `months` between `date1` and `date2`\n",
    "# refer to the example on pp.41-42 for help\n",
    "# write your code below\n",
    "print(date_df.date1.dtype)\n",
    "print(date_df.date2.dtype)\n",
    "\n",
    "# Test if your results are correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df['date2']-date_df['date1'].apply(lambda x: x-np.timedelta64(1,'M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Save the updated `date_df` as a pickle file in the './data' folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![DSB logo](img/Dolan.jpg)\n",
    "# Pandas Data Structure\n",
    "\n",
    "## PD4E Chapter 2\n",
    "### How do you read/manipulate/store data in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![DSB logo](img/Dolan.jpg)\n",
    "# Pandas Basic Plotting\n",
    "\n",
    "## PD4E Chapter 3: Introduction to Plotting\n",
    "### How do you read/manipulate/store data in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What You Learned in Python/Pandas that could Apply Here\n",
    "\n",
    "You will need following knowledge from the first half of this course:\n",
    "1. containers\n",
    "2. using functions\n",
    "3. subsetting and indexing\n",
    "4. classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What You will Learn in this Chapter\n",
    "You will learn following techniques in this chapter:\n",
    "1. `matplotlib`\n",
    "2. `seaborn`\n",
    "3. `Pandas` plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python's Plotting Package: Matplotlib\n",
    "\n",
    "- `matplotlib` is Python's fundamental plotting package\n",
    "    - users have flexible control over elements in plots\n",
    "    - most of the plotting functions are in a sub package called `matplotlib.pyplot`\n",
    "        - we just need to the subpackage, mostly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# below are standardized way of setting the ground for any plotting\n",
    "# import package\n",
    "import matplotlib.pyplot as plt\n",
    "# config the plotting tool\n",
    "# below command makes sure plots appear in a Jupyter notebook\n",
    "%matplotlib inline\n",
    "# set the style for plotting\n",
    "# `ggplot` is the most pupolar plotting tool inhereted from R\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# `seaborn` is another plotting package\n",
    "# here we use it to load the data\n",
    "import seaborn as sns\n",
    "\n",
    "# load data\n",
    "anscombe = sns.load_dataset('anscombe')\n",
    "dataset_1 = anscombe[anscombe['dataset'] == 'I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# the three arguments are x variable, y variable, \n",
    "# and 'o' indicates drawing circles in the scatterplot\n",
    "plt.plot(dataset_1['x'], dataset_1['y'], 'o') # 'o' makes the dots circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Your Turn Here\n",
    "\n",
    "The `anscombe` dataset contains _4_ sub-datasets. Create a visualization containing all _4_ sub-datasets like below.\n",
    "![exercise1](img/PD4E-Ch3-Fig1.png)\n",
    "\n",
    "See tge text book pp. 52 - 55 for more help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Anatomy of a Figure\n",
    "\n",
    "Observe below figure for the terminology of a figure.\n",
    "\n",
    "![example1](img/PD4E-Ch3-Fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistical Visualizations Using Matplotlib\n",
    "\n",
    "Below are different types of visualizations used in analytics:\n",
    "- Univariate\n",
    "    - Histograms\n",
    "- Bivariate\n",
    "    - Scatterplot\n",
    "    - Boxplot\n",
    "- Multivariate (refer to pp. 59 - 61 for an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# load a new dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# histogram\n",
    "fig = plt.figure(figsize=(4,3)) # note that we specify the size the figure\n",
    "axes1 = fig.add_subplot(1,1,1)\n",
    "axes1.hist(tips.total_bill, bins=10) # specify 10 bins in the histogram\n",
    "axes1.set_title('Histogram of Total Bills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# bivariate means two variables\n",
    "# most popular bivariate visualization is scatterplot\n",
    "# use with two continuous variables\n",
    "scatter_plot = plt.figure(figsize=(4, 3))\n",
    "axes2 = scatter_plot.add_subplot(1,1,1)\n",
    "axes2.scatter(tips.total_bill, tips.tip)\n",
    "axes2.set_title('Total Bill vs. Tip')\n",
    "# below statements show you how to set names for x- and y-axis\n",
    "axes2.set_xlabel('Total Bill')\n",
    "axes2.set_xlabel('Tip')\n",
    "# below code show how to show a figure\n",
    "scatter_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Boxplot is an important visualization to show\n",
    "# the relationship between a discrete variable\n",
    "# and a continuous variable\n",
    "box_plot = plt.figure(figsize=(4,3))\n",
    "ax1 = box_plot.add_subplot(1,1,1)\n",
    "ax1.boxplot(\n",
    "    # first argument is the data\n",
    "    # since we are plotting over two pieces of data\n",
    "    # we have to put each piece of data into a list\n",
    "    [tips[tips.sex == 'Female']['tip'],\n",
    "     tips[tips.sex == 'Male']['tip']],\n",
    "    # we can pass in optional parameter to label the data\n",
    "    labels = ['Female', 'Male'])\n",
    "ax1.set_xlabel('Sex')\n",
    "ax1.set_ylabel('Tip')\n",
    "ax1.set_title('Tips by Sex in boxplot')\n",
    "box_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plotting using Seaborn\n",
    "- `Seaborn` is an add-on package building on `matplotlib`\n",
    "    - it is a high-level interface for statistical visualization\n",
    "- `Seaborn` is closely tied with SciPy/PyData (`numpy, scipy, pandas`)\n",
    "- `Seaborn` provides ablity to fine-tune your visuals\n",
    "- we only show a few of `seaborn` examples, for more examples, refer to pp. 63 - 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# below statement is a shortcut for creating the figure object\n",
    "# and add the individual subplot(`ax1`) to the figure\n",
    "hist, ax = plt.subplots()\n",
    "\n",
    "# instead of the `hist()` function from `matplotlib`\n",
    "# we use 'displot()' from `seaborn` - stands for distribution plot\n",
    "ax = sns.distplot(tips.total_bill)\n",
    "ax.set_title('Total Bill Histogram with Density Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# bar plot is another visualization type we use for investigating the distribution of data\n",
    "count, ax = plt.subplots()\n",
    "ax = sns.countplot('day', data=tips)\n",
    "ax.set_title('Count of Days')\n",
    "ax.set_xlabel('Day of the Week')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas Plotting\n",
    "\n",
    "`Pandas` provides a few of built-in plotting methods, which are built on `Matplotlib` as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# histogram\n",
    "tips.total_bill.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# overlay two variables in a histogram\n",
    "tips[['total_bill', 'tip']].plot.hist(alpha=0.5, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# density plot\n",
    "tips.tip.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "tips.plot.scatter(x='total_bill', y='tip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# box plot\n",
    "tips.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Your Turn Here\n",
    "Finish exercises below by following instructions of each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Q1. Coding Problem\n",
    "\n",
    "Using the `tips` dataset, create different visualizations (at least 5 total, with 3 not covered in the lecture). \n",
    "\n",
    "Try to explain what __insights__ you can read off the visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot = plt.figure(figsize=(4,3))\n",
    "ax1 = box_plot.add_subplot(1,1,1)\n",
    "ax1.boxplot([tips[tips.time == 'Lunch']['tip'],\n",
    "    tips[tips.time == 'Dinner']['tip']], labels = ['Dinner', 'Lunch'])\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Tip')\n",
    "ax1.set_title('Tips by Time')\n",
    "box_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.plot.area(y='total_bill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.plot.hexbin(x='tip', y='total_bill', gridsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.plot.scatter(x='size', y='tip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.tip.plot.density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classwork (start here in class)\n",
    "You can start working on them right now:\n",
    "- Read Chapter 2 & 3 in PD4E \n",
    "    - in particular Section 3.6 - since we did not cover it in class \n",
    "- If time permits, start in on your homework. \n",
    "- Ask questions when you need help. Use this time to get help from the professor!\n",
    "\n",
    "# Homework (do at home)\n",
    "The following is due before class next week:\n",
    "  - Any remaining classwork from tonight\n",
    "  - DataCamp Grouping Data assignment\n",
    "\n",
    "Note: All work on DataCamp is logged. Don't try to fake it!\n",
    "\n",
    "Please email [me](mailto:jtao@fairfield.edu) if you have any problems or questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![DSB logo](img/Dolan.jpg)\n",
    "# Pandas Basic Plotting\n",
    "\n",
    "## PD4E Chapter 3: Introduction to Plotting\n",
    "### How do you read/manipulate/store data in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
